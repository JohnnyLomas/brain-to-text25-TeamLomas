{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12491966,"sourceType":"datasetVersion","datasetId":7875034}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport h5py\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport os\n\n# --- Define the base directory ---\nBASE_DIR = '/kaggle/input/brain-to-text-25-data/t15_copyTask_neuralData/hdf5_data_final'\n\nNEURAL_DATA_KEY = 'input_features'\nTRANSCRIPTION_KEY = 'transcription'\n\ndef load_metadata_from_hdf5(file_path):\n    \"\"\"\n    Correctly loads metadata based on the now-known HDF5 structure.\n    \"\"\"\n    metadata = []\n    try:\n        with h5py.File(file_path, 'r') as f:\n            # The top-level keys ARE the trials.\n            for trial_key in f.keys():\n                trial_group = f[trial_key]\n                \n                # Check if the group contains the correct dataset names\n                if isinstance(trial_group, h5py.Group) and NEURAL_DATA_KEY in trial_group and TRANSCRIPTION_KEY in trial_group:\n                    \n                    num_time_bins = trial_group[NEURAL_DATA_KEY].shape[0]\n                    \n                    # The transcription is an array of integers, not a string.\n                    # We will load it as a list of numbers for now.\n                    transcription_ids = list(trial_group[TRANSCRIPTION_KEY][()])\n                    \n                    metadata.append({\n                        'trial_id': trial_key,\n                        'num_time_bins': num_time_bins,\n                        'transcription_ids': transcription_ids,\n                        # We can't get num_words directly yet, so we'll estimate from the length of the ID list.\n                        # This might not be perfect but is a good start.\n                        'num_words_estimate': len(transcription_ids) \n                    })\n    except Exception as e:\n        print(f\"Error processing file {file_path}: {e}\")\n        import traceback\n        traceback.print_exc()\n        \n    return metadata\n\ndef load_test_metadata_from_hdf5(file_path):\n    \"\"\" Loads test data which only has input_features. \"\"\"\n    metadata = []\n    try:\n        with h5py.File(file_path, 'r') as f:\n            for trial_key in f.keys():\n                trial_group = f[trial_key]\n                if isinstance(trial_group, h5py.Group) and NEURAL_DATA_KEY in trial_group:\n                    num_time_bins = trial_group[NEURAL_DATA_KEY].shape[0]\n                    metadata.append({\n                        'trial_id': trial_key,\n                        'num_time_bins': num_time_bins\n                    })\n    except Exception as e:\n        print(f\"Error processing file {file_path}: {e}\")\n    return metadata\n\n\n# --- Main Loading Loop ---\nall_metadata = []\nsession_dirs = sorted([d for d in os.listdir(BASE_DIR) if os.path.isdir(os.path.join(BASE_DIR, d))])\n\nfor session in tqdm(session_dirs, desc=\"Processing Sessions\"):\n    session_path = os.path.join(BASE_DIR, session)\n    for split in ['train', 'val', 'test']:\n        file_name = f'data_{split}.hdf5'\n        file_path = os.path.join(session_path, file_name)\n        \n        if os.path.exists(file_path):\n            if split == 'test':\n                session_metadata = load_test_metadata_from_hdf5(file_path)\n            else:\n                session_metadata = load_metadata_from_hdf5(file_path)\n            \n            # Add session and split info to the found trials\n            for item in session_metadata:\n                item['session'] = session\n                item['split'] = split\n            all_metadata.extend(session_metadata)\n\ndf = pd.DataFrame(all_metadata)\n\n# --- Final Verification and Display ---\nprint(f\"Loaded a total of {len(df)} trials.\")\nif not df.empty:\n    print(f\"Data splits:\\n{df['split'].value_counts()}\")\n    # We no longer have 'sentence_text', so display the new columns\n    display(df.head())\nelse:\n    print(\"DataFrame is still empty. This indicates a very unusual issue.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T15:52:03.065141Z","iopub.execute_input":"2025-08-05T15:52:03.065371Z","iopub.status.idle":"2025-08-05T15:52:56.274365Z","shell.execute_reply.started":"2025-08-05T15:52:03.065354Z","shell.execute_reply":"2025-08-05T15:52:56.273724Z"},"_kg_hide-input":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Processing Sessions:   0%|          | 0/45 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bbe894960244d1d9578fb1eee04f81a"}},"metadata":{}},{"name":"stdout","text":"Loaded a total of 10948 trials.\nData splits:\nsplit\ntrain    8072\ntest     1450\nval      1426\nName: count, dtype: int64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"     trial_id  num_time_bins  \\\n0  trial_0000            321   \n1  trial_0001            481   \n2  trial_0002            480   \n3  trial_0003            502   \n4  trial_0004            402   \n\n                                   transcription_ids  num_words_estimate  \\\n0  [66, 114, 105, 110, 103, 32, 105, 116, 32, 99,...               500.0   \n1  [77, 121, 32, 102, 97, 109, 105, 108, 121, 32,...               500.0   \n2  [87, 104, 97, 116, 32, 100, 111, 32, 116, 104,...               500.0   \n3  [72, 111, 119, 32, 105, 115, 32, 116, 104, 97,...               500.0   \n4  [78, 101, 101, 100, 32, 104, 101, 108, 112, 32...               500.0   \n\n          session  split  \n0  t15.2023.08.11  train  \n1  t15.2023.08.11  train  \n2  t15.2023.08.11  train  \n3  t15.2023.08.11  train  \n4  t15.2023.08.11  train  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trial_id</th>\n      <th>num_time_bins</th>\n      <th>transcription_ids</th>\n      <th>num_words_estimate</th>\n      <th>session</th>\n      <th>split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>trial_0000</td>\n      <td>321</td>\n      <td>[66, 114, 105, 110, 103, 32, 105, 116, 32, 99,...</td>\n      <td>500.0</td>\n      <td>t15.2023.08.11</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>trial_0001</td>\n      <td>481</td>\n      <td>[77, 121, 32, 102, 97, 109, 105, 108, 121, 32,...</td>\n      <td>500.0</td>\n      <td>t15.2023.08.11</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>trial_0002</td>\n      <td>480</td>\n      <td>[87, 104, 97, 116, 32, 100, 111, 32, 116, 104,...</td>\n      <td>500.0</td>\n      <td>t15.2023.08.11</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>trial_0003</td>\n      <td>502</td>\n      <td>[72, 111, 119, 32, 105, 115, 32, 116, 104, 97,...</td>\n      <td>500.0</td>\n      <td>t15.2023.08.11</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>trial_0004</td>\n      <td>402</td>\n      <td>[78, 101, 101, 100, 32, 104, 101, 108, 112, 32...</td>\n      <td>500.0</td>\n      <td>t15.2023.08.11</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-05T12:19:56.839167Z","iopub.status.idle":"2025-08-05T12:19:56.839628Z","shell.execute_reply.started":"2025-08-05T12:19:56.839446Z","shell.execute_reply":"2025-08-05T12:19:56.839462Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T12:19:56.843580Z","iopub.status.idle":"2025-08-05T12:19:56.843980Z","shell.execute_reply.started":"2025-08-05T12:19:56.843767Z","shell.execute_reply":"2025-08-05T12:19:56.843783Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import h5py\nimport sys\n\ndef load_h5py_file(file_path):\n    data = {\n        'neural_features': [],\n        'n_time_steps': [],\n        'seq_class_ids': [],\n        'seq_len': [],\n        'transcriptions': [],\n        'sentence_label': [],\n        'session': [],\n        'block_num': [],\n        'trial_num': [],\n        'corpus': [],\n    }\n    # Open the hdf5 file for that day\n    with h5py.File(file_path, 'r') as f:\n\n        keys = list(f.keys())\n\n        # For each trial in the selected trials in that day\n        for key in keys:\n            g = f[key]\n\n            neural_features = g['input_features'][:]\n            n_time_steps = g.attrs['n_time_steps']\n            seq_class_ids = g['seq_class_ids'][:] if 'seq_class_ids' in g else None\n            seq_len = g.attrs['seq_len'] if 'seq_len' in g.attrs else None\n            transcription = g['transcription'][:] if 'transcription' in g else None\n            sentence_label = g.attrs['sentence_label'][:] if 'sentence_label' in g.attrs else None\n            session = g.attrs['session']\n            block_num = g.attrs['block_num']\n            trial_num = g.attrs['trial_num']\n\n            # match this trial up with the csv to get the corpus name\n            year, month, day = session.split('.')[1:]\n            date = f'{year}-{month}-{day}'\n\n            data['neural_features'].append(neural_features)\n            data['n_time_steps'].append(n_time_steps)\n            data['seq_class_ids'].append(seq_class_ids)\n            data['seq_len'].append(seq_len)\n            data['transcriptions'].append(transcription)\n            data['sentence_label'].append(sentence_label)\n            data['session'].append(session)\n            data['block_num'].append(block_num)\n            data['trial_num'].append(trial_num)\n    return data\n\n#Generate all referencable file names in the main dataset, split into train, test, and val.\ndef generate_file_names(BASE_DIR):\n    file_names_train = []\n    file_names_test = []\n    file_names_val = []\n    for folder in os.listdir(BASE_DIR):\n        folder_name = BASE_DIR + '/' + folder\n        for file in os.listdir(folder_name):\n            file_name = BASE_DIR + '/' + folder + '/' + file\n            if file == 'data_train.hdf5':\n                file_names_train.append(file_name)\n            elif file == 'data_test.hdf5':\n                file_names_test.append(file_name)\n            elif file == 'data_val.hdf5':\n                file_names_val.append(file_name)\n            else:\n                raise Exception('Unrecognized file name')\n            \n\n    return file_names_train, file_names_test, file_names_val\n\n\nfile_names_train, file_names_test, file_names_val = generate_file_names(BASE_DIR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T15:53:01.207541Z","iopub.execute_input":"2025-08-05T15:53:01.207959Z","iopub.status.idle":"2025-08-05T15:53:01.327892Z","shell.execute_reply.started":"2025-08-05T15:53:01.207939Z","shell.execute_reply":"2025-08-05T15:53:01.327082Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\nfrom kaggle_secrets import UserSecretsClient\nfrom peft import IA3Config, get_peft_model\nimport os\nimport h5py\nimport re\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n\nNEURAL_DATA_KEY = 'input_features'\nTRANSCRIPTION_KEY = 'transcription'\n\n# Metadata loading function provided by competition host\ndef load_metadata_from_hdf5(file_path):\n    \"\"\"\n    Correctly loads metadata based on the now-known HDF5 structure.\n    \"\"\"\n    metadata = []\n    try:\n        with h5py.File(file_path, 'r') as f:\n            # The top-level keys ARE the trials.\n            for trial_key in f.keys():\n                trial_group = f[trial_key]\n                \n                # Check if the group contains the correct dataset names\n                if isinstance(trial_group, h5py.Group) and NEURAL_DATA_KEY in trial_group and TRANSCRIPTION_KEY in trial_group:\n                    \n                    num_time_bins = trial_group[NEURAL_DATA_KEY].shape[0]\n                    \n                    # The transcription is an array of integers, not a string.\n                    # We will load it as a list of numbers for now.\n                    transcription_ids = list(trial_group[TRANSCRIPTION_KEY][()])\n                    \n                    metadata.append({\n                        'trial_id': trial_key,\n                        'num_time_bins': num_time_bins,\n                        'transcription_ids': transcription_ids,\n                        # We can't get num_words directly yet, so we'll estimate from the length of the ID list.\n                        # This might not be perfect but is a good start.\n                        'num_words_estimate': len(transcription_ids) \n                    })\n    except Exception as e:\n        print(f\"Error processing file {file_path}: {e}\")\n        import traceback\n        traceback.print_exc()\n        \n    return metadata\n\n# Metadata loading function provided by competition host\ndef load_test_metadata_from_hdf5(file_path):\n    \"\"\" Loads test data which only has input_features. \"\"\"\n    metadata = []\n    try:\n        with h5py.File(file_path, 'r') as f:\n            for trial_key in f.keys():\n                trial_group = f[trial_key]\n                if isinstance(trial_group, h5py.Group) and NEURAL_DATA_KEY in trial_group:\n                    num_time_bins = trial_group[NEURAL_DATA_KEY].shape[0]\n                    metadata.append({\n                        'trial_id': trial_key,\n                        'num_time_bins': num_time_bins\n                    })\n    except Exception as e:\n        print(f\"Error processing file {file_path}: {e}\")\n    return metadata\n\ndef decode_transcription(ids: np.ndarray) -> str:\n    \"\"\"\n    Converts a NumPy array of ASCII character IDs to a string, \n    stopping at the first null (0) character.\n    \"\"\"\n    if not isinstance(ids, np.ndarray):\n        ids = np.array(ids, dtype=np.uint8)\n\n    zero_indices = np.where(ids == 0)[0]\n    end = zero_indices[0] if zero_indices.size > 0 else len(ids)\n    return \"\".join(map(chr, ids[:end]))\n\n\nclass b2tDataset(Dataset):\n    \n    '''\n    Provides a dataset for accessing training, validation, and test data.\n    \n    sets: [train|val|test] specifies the split held by the dataset\n    dir:  [str] directory to search for hdf5 data files\n    '''\n    def __init__(self, \n                 sets=\"train\",\n                 dir=\"/kaggle/input/brain-to-text-25-data/t15_copyTask_neuralData/hdf5_data_final/\",\n                 tokenizer = None\n                ):\n        \n        self.set_type = sets\n        self.files = []\n        self.session_counts = []\n        self.all_metadata = []\n\n        '''if tokenizer != None:\n            self.tokenizer = tokenizer\n        else:\n            self.tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")'''\n    \n        #Get a list of files for the datasplit\n        for dirname, _, filenames in os.walk(dir):\n            for filename in filenames:\n                if self.set_type in filename:\n                    self.files.append(os.path.join(dirname, filename))\n\n        # Get metadata for the files in the dataset\n        for file_path in tqdm(self.files, desc=\"Processing sessions\"):\n            if os.path.exists(file_path):\n                if self.set_type == 'test':\n                    session_metadata = load_test_metadata_from_hdf5(file_path)\n                else:\n                    session_metadata = load_metadata_from_hdf5(file_path)\n                \n                self.session_counts.append(len(session_metadata))\n                self.all_metadata.extend(session_metadata) \n    \n    def __len__(self):\n        return sum(self.session_counts)\n\n    def __getitem__(self, idx):\n        total = 0\n        for i,count in enumerate(self.session_counts):\n            total += count\n            if total > idx:\n                break\n        file = self.files[i]\n        index = idx - total + count\n\n        target = None\n        with h5py.File(file, 'r') as f:\n            inputs = torch.from_numpy(f[list(f.keys())[index]]['input_features'][:])\n            if self.set_type != \"test\":\n                target = f[list(f.keys())[index]]['transcription'][:]\n\n        target = decode_transcription(target)\n        #target = self.tokenizer.encode(target, return_tensors=\"pt\")\n        \n        return (inputs, target)\n\n    def __getiteminputs__(self,idx):\n        total = 0\n        for i,count in enumerate(self.session_counts):\n            total += count\n            if total > idx:\n                break\n        file = self.files[i]\n        index = idx - total + count\n\n        with h5py.File(file, 'r') as f:\n            inputs = torch.from_numpy(f[list(f.keys())[index]]['input_features'][:])\n       \n        return inputs \n    \n\n# Custom collation function to handle variable seq lengths\ndef b2tCollate_fn(batch):\n    inputs, targets = zip(*batch)\n\n    max_input_len = max([inp.shape[0] for inp in inputs])\n    max_target_len = max([target.shape[1] for target in targets])\n\n    # Compute attention-masks\n    attn_masks = [torch.ones(inp.shape[0]) for inp in inputs]\n    attn_masks = [F.pad(mask, (0,max_input_len-mask.shape[0])) for mask in attn_masks]\n    attn_masks = torch.stack(attn_masks)\n    \n    # Pad and stack the input signals\n    inputs = [F.pad(inp, (0,0,0,max_input_len-inp.shape[0])) for inp in inputs]\n    inputs = torch.stack(inputs)\n    \n    # Pad and stack the target sentences\n    targets = [F.pad(target, (0,max_target_len-target.shape[1])) for target in targets]\n    targets = torch.stack(targets).squeeze()\n\n    return (inputs, attn_masks, targets)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T15:53:06.059023Z","iopub.execute_input":"2025-08-05T15:53:06.059275Z","iopub.status.idle":"2025-08-05T15:53:33.141935Z","shell.execute_reply.started":"2025-08-05T15:53:06.059255Z","shell.execute_reply":"2025-08-05T15:53:33.140950Z"}},"outputs":[{"name":"stderr","text":"2025-08-05 15:53:20.644985: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754409200.867223      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754409200.933634      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"Generate datasets used to create the graphs.","metadata":{}},{"cell_type":"markdown","source":"What questions are interesting for variance?\n1. Variance across the whole dataset in terms of length\n2. Variance across each file (day)\n3. Variance in terms of particpant (is this the same as the day?)\n   ","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ntraining_data = b2tDataset(sets=\"train\")\nlengths_vs_target = []\nfor i in range(training_data.__len__()):\n    #look at dataloader, see if it's faster\n    input_features,target = training_data.__getitem__(i)\n    lengths_vs_target.append((input_features.shape[0], target))\n\nlengths_arr = np.array([], dtype=int)\ntargets_arr = np.array([], dtype=str)\ntargets_length_arr = np.array([], dtype=int)\nfor i in lengths_vs_target:\n    lengths_arr = np.append(lengths_arr,int(i[0]))\n    targets_arr = np.append(targets_arr,str(i[1]))\n    targets_length_arr = np.append(targets_length_arr,len(i[1]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T16:17:38.453375Z","iopub.execute_input":"2025-08-05T16:17:38.453569Z","iopub.status.idle":"2025-08-05T16:42:23.979281Z","shell.execute_reply.started":"2025-08-05T16:17:38.453554Z","shell.execute_reply":"2025-08-05T16:42:23.978204Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Processing sessions:   0%|          | 0/45 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6b256d0ddd7460faef98e6a0767fd9f"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"print(\"Mean timeseries length: \" + str(lengths_arr.mean()))\nprint(\"Max timeseries length: \" + str(lengths_arr.max()))\nprint(\"Min timeseries length: \" + str(lengths_arr.min()))\nprint(\"Variance across all timeseries: \" + str(np.var(lengths_arr))) #change to stdev","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T16:42:23.980700Z","iopub.execute_input":"2025-08-05T16:42:23.980956Z","iopub.status.idle":"2025-08-05T16:42:23.986345Z","shell.execute_reply.started":"2025-08-05T16:42:23.980936Z","shell.execute_reply":"2025-08-05T16:42:23.985665Z"}},"outputs":[{"name":"stdout","text":"Mean timeseries length: 874.8405599603568\nMax timeseries length: 2475\nMin timeseries length: 138\nVariance across all timeseries: 95035.90309720873\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"Variance is high!","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import pearsonr\n\ncorr, _ = pearsonr(lengths_arr, targets_length_arr)\n\nplt.scatter(lengths_arr, targets_length_arr)\nplt.title(f\"Scatter plot showing correlation between timeseries length and target length with correlation = {corr:.2f}\")\nplt.xlabel(\"Timeseries Length\")\nplt.ylabel(\"Target Length\")\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T13:29:51.840852Z","iopub.execute_input":"2025-08-05T13:29:51.841204Z","iopub.status.idle":"2025-08-05T13:29:52.070043Z","shell.execute_reply.started":"2025-08-05T13:29:51.841172Z","shell.execute_reply":"2025-08-05T13:29:52.069177Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This shows that there is a fairly strong correlation between timeseries length and target sentence length, with the Pearson's Correlation Coefficient of 0.71. But you may be wondering, what are those outliers? What are the long sentences? And which sentences relate to the longest timeseries? Let's take a look at that.","metadata":{}},{"cell_type":"code","source":"print(\"Sentences with Length Greater than 80 Characters: \\n\")\ncount = 0\n\nfor i in lengths_vs_target:\n    if len(i[1]) > 80:\n        print(\"Sentence \" + str(count) + \": \" + i[1])\n        count += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T13:29:59.995505Z","iopub.execute_input":"2025-08-05T13:29:59.995783Z","iopub.status.idle":"2025-08-05T13:30:00.003998Z","shell.execute_reply.started":"2025-08-05T13:29:59.995763Z","shell.execute_reply":"2025-08-05T13:30:00.003155Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Interestingly, the sentences above are all testing sentences it seems, potentially before the participant was ready. Should we throw these out? I feel like there's a chance they will throw off the data.","metadata":{}},{"cell_type":"markdown","source":"One thing I am intrigued by is whether the longest timeseries length sentences relate to more complex sentences. Let's look at the longest timeseries.","metadata":{}},{"cell_type":"code","source":"print(\"Sentences with Timeseries Length greater than 2000\")\n\ncount = 0\nfor i in lengths_vs_target:\n    if int(i[0]) > 2000:\n        print(\"Sentence \" + str(count) + \": \" + i[1] + \" Timeseries length: \" + str(i[0]))\n        count += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T13:30:31.598433Z","iopub.execute_input":"2025-08-05T13:30:31.599334Z","iopub.status.idle":"2025-08-05T13:30:31.607118Z","shell.execute_reply.started":"2025-08-05T13:30:31.599301Z","shell.execute_reply":"2025-08-05T13:30:31.606145Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Interestingly, some of these sentences seem to relate to complex ideas: \"This is not a suitable method to measure and rank the value of coins.\" and \"The Dallas Cowboys are going to have a problem if their quarterback gets hurt.\" while some seem to relate to very simple things \"I like how they tell it.\" and \"If they work at it a little bit.\" Note to check in on how the study was conducted, how did they decide how long to pull in timeseries data? The brain likely doesn't just go blank once the thought is complete, so was it up to the study director to decide when to stop recording?","metadata":{}},{"cell_type":"code","source":"print(\"Sentences with Timeseries Length less than 300: \\n\")\n\ncount = 0\nfor i in lengths_vs_target:\n    if int(i[0]) < 300:\n        print(\"Sentence \" + str(count) + \": \" + i[1] + \" Timeseries length: \" + i[0])\n        count += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T12:46:47.136639Z","iopub.execute_input":"2025-08-05T12:46:47.136987Z","iopub.status.idle":"2025-08-05T12:46:47.151117Z","shell.execute_reply.started":"2025-08-05T12:46:47.136953Z","shell.execute_reply":"2025-08-05T12:46:47.150239Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"What is the meaning of those [DO NOTHING] and [RIGHT HAND - CLOSE]? And what is up with \"What's his whim to decide it should be two months?\" That seems to be a strangely long sentence for the timeseries length, as well as being a strange phrasing. It doesn't seem like incredibly natural speech to me, might need to throw that piece of data out too.","metadata":{}},{"cell_type":"markdown","source":"Might need to tweak the model so that it relies more on the single words than the context, because the sentence correlations are not strong. ","metadata":{}}]}